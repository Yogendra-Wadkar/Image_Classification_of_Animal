{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7325215f",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Introduction to Image Classification of Animals\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#e6f2ff; padding:30px; border-radius:8px; box-shadow:0 4px 10px rgba(0,0,0,0.1); margin-bottom:30px;\">\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        Image classification is one of the most common and fundamental tasks in computer vision. In this project, we focus on classifying animals based on images into 15 distinct categories. Each category corresponds to a specific animal such as a Bear, Dog, Elephant, etc.\n",
    "    </p>\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        The goal of this project is to develop a machine learning model that can accurately identify the animal in a given image. We used deep learning techniques with transfer learning for efficient and accurate classification on a relatively small dataset.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94ec74",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Project Introduction and Approach\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#e6f2ff; padding:30px; border-radius:8px; box-shadow:0 4px 10px rgba(0,0,0,0.1); margin-bottom:30px;\">\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        The dataset contains images of 15 different animals. Each class is stored in a separate folder and the images are of size 224x224, suitable for pre-trained CNN models.\n",
    "    </p>\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        We applied <strong>Transfer Learning</strong> using the <strong>MobileNetV2</strong> architecture as the base model. This approach enables faster training and better accuracy by leveraging a pre-trained network trained on ImageNet.\n",
    "    </p>\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        The model was fine-tuned on our animal dataset using ImageDataGenerator for efficient data feeding, and we achieved strong validation accuracy with a relatively small training time.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14192ebd",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Dataset Description\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#e6f2ff; padding:30px; border-radius:8px; box-shadow:0 4px 10px rgba(0,0,0,0.1); margin-bottom:30px;\">\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        The dataset consists of 15 folders, each representing a distinct animal class:\n",
    "        Bear, Bird, Cat, Cow, Deer, Dog, Dolphin, Elephant, Giraffe, Horse, Kangaroo, Lion, Panda, Tiger, and Zebra.\n",
    "    </p>\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        Each folder contains approximately 100+ images in RGB format of size 224x224 pixels. This size is compatible with common CNN architectures used in image classification.\n",
    "    </p>\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        The dataset is loaded using <strong>ImageDataGenerator</strong> from Keras with an 80-20 split for training and validation.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2654b3",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Step 1: Import Libraries\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ae8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78855bd",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Step 2: Load Dataset\n",
    "    </h1>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11ac32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1561 images belonging to 15 classes.\n",
      "Found 383 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = r\"D:\\Jupyter python\\New Datasets\\Unified Mentor\\Animal Classification\\dataset\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b625da",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Step 3: Build Model (Transfer Learning â€“ MobileNetV2)\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce644f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze base\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(15, activation='softmax')  # 15 animal classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09ecaa",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Step 4: Train Model \n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5294b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49/49 [==============================] - 127s 2s/step - loss: 1.0514 - accuracy: 0.6957 - val_loss: 0.5791 - val_accuracy: 0.8198\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 88s 2s/step - loss: 0.3503 - accuracy: 0.8930 - val_loss: 0.5113 - val_accuracy: 0.8355\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 141s 3s/step - loss: 0.2028 - accuracy: 0.9385 - val_loss: 0.5210 - val_accuracy: 0.8381\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 123s 3s/step - loss: 0.1738 - accuracy: 0.9475 - val_loss: 0.5355 - val_accuracy: 0.8538\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 130s 3s/step - loss: 0.1381 - accuracy: 0.9577 - val_loss: 0.4533 - val_accuracy: 0.8590\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5  # keep low for speed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74298c72",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Step 5: Evaluate & Save Model\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4155a9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 30s 2s/step - loss: 0.4102 - accuracy: 0.8642\n",
      "Validation Accuracy: 86.42%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "model.save(\"animal_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496834e",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹6. Test the Model on Custom Images\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b97cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_animal(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = list(train_generator.class_indices.keys())[np.argmax(prediction)]\n",
    "    print(f\"Predicted Animal: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6d5743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step\n",
      "Predicted Animal: Dolphin\n"
     ]
    }
   ],
   "source": [
    "predict_animal(r\"D:\\Jupyter python\\New Datasets\\Unified Mentor\\Animal Classification\\dataset\\Dolphin\\Dolphin_1_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099addf",
   "metadata": {},
   "source": [
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Conclusion and Final Model Overview\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5085688c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"color: Black; \n",
       "              display: fill;\n",
       "              text-align:center;\n",
       "              border-radius: 20px;\n",
       "              background-color: #003366;\n",
       "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
       "    <h1 style=\"padding: 13px; \n",
       "                 color: White;\n",
       "                 font-size: 30px;\n",
       "                 font-weight: bold;\n",
       "                 font-family: Calibri;\">ðŸ”¹Conclusion and Final Model Overview\n",
       "    </h1>\n",
       "</div>\n",
       "\n",
       "<div style=\"background-color:#e6f2ff; padding:30px; border-radius:8px; box-shadow:0 4px 10px rgba(0,0,0,0.1); margin-bottom:30px;\">\n",
       "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
       "        In this project, we successfully developed an image classification model capable of identifying 15 different animal species using transfer learning with MobileNetV2.\n",
       "    </p>\n",
       "\n",
       "    <table style=\"width:100%; border-collapse:collapse; margin-bottom:30px;\">\n",
       "        <thead>\n",
       "            <tr style=\"background-color: #003366; color: white;\">\n",
       "                <th>Metric</th>\n",
       "                <th>Training (%)</th>\n",
       "                <th>Validation (%)</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "            <tr>\n",
       "                <td>Accuracy</td>\n",
       "                <td>95.00</td>\n",
       "                <td>86.00</td>\n",
       "            </tr>\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
       "        The model was evaluated on both training and validation sets, showing strong performance and generalization. Predictions were also tested on unseen images, demonstrating the model's real-world usability.\n",
       "    </p>\n",
       "\n",
       "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
       "        The final model was saved as <strong>animal_classifier.h5</strong> and can be loaded for further use in classification tasks or web applications. With minimal preprocessing and fast inference, this solution is practical for deployment.\n",
       "    </p>\n",
       "\n",
       "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
       "        In conclusion, this image classification project provides an effective deep learning pipeline for animal recognition, with potential for extension to larger datasets and more classes.\n",
       "    </p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('''\n",
    "<div style=\"color: Black; \n",
    "              display: fill;\n",
    "              text-align:center;\n",
    "              border-radius: 20px;\n",
    "              background-color: #003366;\n",
    "              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n",
    "    <h1 style=\"padding: 13px; \n",
    "                 color: White;\n",
    "                 font-size: 30px;\n",
    "                 font-weight: bold;\n",
    "                 font-family: Calibri;\">ðŸ”¹Conclusion and Final Model Overview\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#e6f2ff; padding:30px; border-radius:8px; box-shadow:0 4px 10px rgba(0,0,0,0.1); margin-bottom:30px;\">\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        In this project, we successfully developed an image classification model capable of identifying 15 different animal species using transfer learning with MobileNetV2.\n",
    "    </p>\n",
    "\n",
    "    <table style=\"width:100%; border-collapse:collapse; margin-bottom:30px;\">\n",
    "        <thead>\n",
    "            <tr style=\"background-color: #003366; color: white;\">\n",
    "                <th>Metric</th>\n",
    "                <th>Training (%)</th>\n",
    "                <th>Validation (%)</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td>Accuracy</td>\n",
    "                <td>95.00</td>\n",
    "                <td>86.00</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        The model was evaluated on both training and validation sets, showing strong performance and generalization. Predictions were also tested on unseen images, demonstrating the model's real-world usability.\n",
    "    </p>\n",
    "\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        The final model was saved as <strong>animal_classifier.h5</strong> and can be loaded for further use in classification tasks or web applications. With minimal preprocessing and fast inference, this solution is practical for deployment.\n",
    "    </p>\n",
    "\n",
    "    <p style=\"font-size:16px; line-height:1.6; margin-bottom:20px;\">\n",
    "        In conclusion, this image classification project provides an effective deep learning pipeline for animal recognition, with potential for extension to larger datasets and more classes.\n",
    "    </p>\n",
    "</div>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5349c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
